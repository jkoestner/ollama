{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "364959f2-78db-48a9-aeb5-ed08a19ab98c",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5330c09f-9907-45cd-a62f-8e394ee1b580",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "os.chdir(\"../\")\n",
    "os.getcwd()\n",
    "# import working directory before going to other locations\n",
    "sys.path.insert(0, os.getcwd())  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "447daf8a-7140-40e4-93b4-af5fa7cd7c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from osllmh import engine, vector_stores\n",
    "from osllmh.utils import custom_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bce989e4-fcb9-4ddd-8ace-fd0bfb377ba5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# update log level if wanting more logging\n",
    "custom_logger.set_log_level(\"DEBUG\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1be1ca1-a0bb-47fa-9f52-5d5c4b237e7a",
   "metadata": {},
   "source": [
    "# Engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de97faaa-c8d0-4a2b-95d1-2fb84a6e6709",
   "metadata": {},
   "source": [
    "## Create Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "7bd7939b-f35d-4a7f-98a7-6cafcfdb9204",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Loaded settings with project: `personal`, vector_type: `qdrant`, and url... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Setting up the tokenizer... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Loading existing index from storage... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Creating response synthesizer with reponse_mode: compact... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Creating query engine... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:04:57 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Using custom prompt: compact... \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "e = engine.Engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "9a68ef05-5539-4871-b0e6-22b17329cae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m 2024-12-14 01:04:58 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Updating index with new documents from C:\\Users\\johnk\\Desktop\\github\\osllmh\\files\\personal... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:05:02 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Loading existing index from storage with qdrant`... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:05:03 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Adding 0 new documents to the index... \u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2e294f0b7204cd8a4857e29b0e1a07e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Indexing documents: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m 2024-12-14 01:05:03 \u001b[0m|\u001b[37m osllmh.vector_stores \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Index updated and persisted. \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:05:03 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Creating response synthesizer with reponse_mode: compact... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:05:03 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Creating query engine... \u001b[0m\n",
      "\u001b[37m 2024-12-14 01:05:03 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Using custom prompt: compact... \u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<llama_index.core.indices.vector_store.base.VectorStoreIndex at 0x1a58540e940>"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.create_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "bdf41646-aa9b-4307-b35d-226a7a08a357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m 2024-12-14 00:23:34 \u001b[0m|\u001b[37m osllmh.engine \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m metadata for 3 sources \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "response = e.query(\"what is the best sentence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "da52181c-2c64-4c7c-b503-2ce4c8f9eba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The best sentence is: \"The rationale consists of explaining why the rule—and its consequences—exist.\" This sentence highlights the importance of providing a cognitive rationale to children, which enhances their understanding and compliance with rules.'"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff5118f-755d-43eb-b0f7-5b2d60cfe7fb",
   "metadata": {},
   "source": [
    "## Vector Maintenance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5f4c6386-948b-4077-82d4-f01996dc6588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'file_path': 'C:\\\\Users\\\\johnk\\\\Desktop\\\\github\\\\osllmh\\\\files\\\\personal\\\\books\\\\The New Father - Armin A. Brott.epub',\n",
       "  'doc_id': '1c9bde40-a44f-4694-a558-a51d898ecd38'},\n",
       " {'file_path': 'C:\\\\Users\\\\johnk\\\\Desktop\\\\github\\\\osllmh\\\\files\\\\personal\\\\books\\\\Brain Rules for Baby_ How to Raise a Smart and Happy Child From Zero to Five - John Medina.epub',\n",
       "  'doc_id': '1eaa30a2-d53c-4bff-94c2-ef2be58646a1'},\n",
       " {'file_path': 'C:\\\\Users\\\\johnk\\\\Desktop\\\\github\\\\osllmh\\\\files\\\\personal\\\\books\\\\AI 2041_ Ten Visions for Our Future - Kai-Fu Lee.epub',\n",
       "  'doc_id': 'dcaae3fe-9c39-4fdc-b687-2ca2ff462c14'}]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.vector_provider.list_files_from_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "39c43694-22c9-4917-912d-6c704398fbfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionsResponse(collections=[CollectionDescription(name='personal'), CollectionDescription(name='actuary'), CollectionDescription(name='aa')])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.vector_provider.client.get_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b0371d-b8fb-41f3-8a64-2e2215986375",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e.vector_provider.delete_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "de7fbc4e-11c3-4154-8e6b-7c035a2384a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[37m 2024-12-14 01:04:42 \u001b[0m|\u001b[37m osllmh.vector_stores \u001b[0m|\u001b[32m INFO     \u001b[0m|\u001b[32m Deleting document with ID: 9d1bb40f-03b7-4bdc-b354-e9045c715e9d \u001b[0m\n"
     ]
    }
   ],
   "source": [
    "e.vector_provider.delete_document('9d1bb40f-03b7-4bdc-b354-e9045c715e9d')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbb4002-e333-4854-9b4a-f0b502841430",
   "metadata": {},
   "source": [
    "# Test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78566a8-53b0-4ea1-b662-1d2d0653e115",
   "metadata": {},
   "source": [
    "# Reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c41d79d4-21c5-4ad4-953a-1dcf7dd165bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "8f20638c-e4e8-4066-9dab-04c7867d5fa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'osllmh.vector_stores' from 'C:\\\\Users\\\\johnk\\\\Desktop\\\\github\\\\osllmh\\\\osllmh\\\\vector_stores.py'>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(engine)\n",
    "importlib.reload(vector_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9051282-fd87-45bb-a0a9-ea246f7114b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "osllmh",
   "language": "python",
   "name": "osllmh"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
